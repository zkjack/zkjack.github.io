---
layout: post
title:  "模型评估与选择"
categories: jekyll update
---

_______________________________________________________________________________

# 经验误差与过拟合：

* 学习器在训练集上的误差称为经验误差，在新样本上的误差称为泛化误差。我们实际能做的是努力使经验误差最小化，但我们期望的是在新样本上能表现很好的学习器。
       
* 在新样本上，学习器学习能力过于强大，以至于把训练样本所包含的不太一般的特性都学到了的现象称为过拟合。相对应学习器不能学好训练样本的一般特性称为欠拟合。

# 评估方法：
* 测试集和训练集划分：
留出法：将数据集D划分为两个互斥的集合，一般2/3-4/5用于训练，剩下的用于测试，采样需要保持数据分布的一致性，一般采用若干次随机分层采样，重复进行试验评估后取平均值作为留出法的评估结果。
       
交叉验证法：将数据集D划分为k个大小相似的互斥子集，每个子集保持数据分布一致性，即从D中分层采样得到。每次用k-1个子集作为训练集，剩下作为测试集，最后返回k次训练结果的均值。k常取5、10、20。并进行重复测试，称为“p次k折交叉验证”。常见的有10次10折交叉验证。
      
自助法：每次从数据集D中挑选一个样本放入D’，然后再放回D中。进行m次抽取后约36.8%的样本未出现在D’中，D’用于训练，D\D’用于测试集。
      
总结：自助法在数据集小时很有用，且有利于集成学习，但会引入估计偏差。数据量足够时通常采用留出法和交叉验证法。

* 调参与最终模型
> 对算法参数进行设定的过程称为参数调节，参数调的好不好往往对最终模型性能有关键性影响。
> 在研究对比不同算法的泛化性能时，我们用测试集上的判别效果来估计模型在实际使用时的泛化能力，而把训练数据另外划分为训练集和验证集，基于验证集上的性能来进行模型选择和调参。

# 性能度量
* 错误率与精度
错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例。

* 查准率、查全率与F1
学习器预测类别的组合分为真正例（TP）、假正例（FP）、真反例（TN）、假反例（FN）。查准率P = `TP/(TP+FP)`、查全率`R = TP/(TP+FN)`。以查准率为纵轴、查全率为横轴作图得到“P-R曲线”，一个学习器曲线面积的大小在一定程度上表征了学习器性能的优劣。查准率=查全率时的取值称为平衡点（BEP），BEP的大的学习器优于小的学习器。`F1 = 2*P*R/(P+R)`。F1的大小反映了学习器的优劣。

* ROC与AUC
受试者工作特征（ROC）曲线的纵轴是真正例率`TPR=TP/(TP+FN)`,横轴是假正例率`FPR = FP/(FP+TN)`。ROC曲线的面积AUC（Area Under Curve）的大小反映学习器性能的优劣。

# 比较检验：
* 假设检验：与线性代数假设检验相同。
* 交叉验证t检验与McNemar检验：都是在一个数据集上比较两个算法的性能。
* Friedman检验：在一个数据集上比较多个算法，若“所有的算法性能相同”这个假设被拒绝，则说明算法的性能显著不同，这时可使用“后续检验”来进一步区分各算法。比如：Nemenyi后续检验。

# 泛化误差

* 泛化误差可分解为偏差、方差与噪声之和。偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响，噪声表达了当前任务上任何学习算法所能达到的期望泛化误差的下届，即刻画了学习问题本身的难度。

